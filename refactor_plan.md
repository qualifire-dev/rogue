# Rogue Agent Evaluator - Server-Client Architecture Refactor Plan

## Overview

This document outlines the comprehensive plan to refactor the Rogue Agent Evaluator from a monolithic architecture to a server-client architecture with multiple frontend options including CLI, Gradio UI, Go TUI, and pytest plugin.

**Inspiration**: This refactor draws heavily from [OpenCode's architecture](https://github.com/sst/opencode), which successfully implements a similar client-server pattern with multiple frontends and language-specific SDKs.

## Current Architecture Analysis

### Existing Components
- **Monolithic Structure**: All components tightly coupled in single `rogue/` package
- **Direct Integration**: CLI and UI directly invoke evaluation logic
- **ADK Agent**: Embedded within the application flow
- **Limited Frontend Options**: Only CLI and Gradio UI available

### Pain Points
- Difficult to add new frontend types
- Tight coupling between UI and evaluation logic
- No API for third-party integrations
- Limited scalability for concurrent evaluations

## Target Architecture (OpenCode-Inspired)

### High-Level Design
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontends     â”‚    â”‚   Rogue Server  â”‚    â”‚   ADK Agent     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ CLI (Python)  â”‚    â”‚ â€¢ HTTP API      â”‚    â”‚ â€¢ Evaluation    â”‚
â”‚ â€¢ Gradio UI     â”‚â—„â”€â”€â–ºâ”‚ â€¢ WebSocket     â”‚â—„â”€â”€â–ºâ”‚   Logic         â”‚
â”‚ â€¢ TUI (Go)      â”‚    â”‚ â€¢ Process Mgmt  â”‚    â”‚ â€¢ Policy Check  â”‚
â”‚ â€¢ Pytest Pluginâ”‚    â”‚ â€¢ Session Mgmt  â”‚    â”‚ â€¢ ADK Framework â”‚
â”‚ â€¢ VSCode Ext    â”‚    â”‚ â€¢ Bus System    â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                       â–²
         â”‚                       â”‚
         â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Packages      â”‚    â”‚   Data Models   â”‚
â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Python SDK    â”‚    â”‚ â€¢ Scenarios     â”‚
â”‚ â€¢ TypeScript SDKâ”‚    â”‚ â€¢ Results       â”‚
â”‚ â€¢ Go SDK        â”‚    â”‚ â€¢ Configuration â”‚
â”‚ â€¢ Function Pkg  â”‚    â”‚ â€¢ Chat History  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## New Folder Structure (OpenCode-Inspired with FastAPI)

```
qualifire-agent-evaluator-1/
â”œâ”€â”€ rogue/                             # Core Python server package
â”‚   â”œâ”€â”€ server/                        # FastAPI server
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                    # FastAPI application
â”‚   â”‚   â”œâ”€â”€ api/                       # API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluations.py
â”‚   â”‚   â”‚   â”œâ”€â”€ scenarios.py
â”‚   â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ core/                      # Core business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ orchestrator.py        # Evaluation orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ session_manager.py     # Session management
â”‚   â”‚   â”‚   â”œâ”€â”€ agent_invoker.py       # ADK agent process management
â”‚   â”‚   â”‚   â””â”€â”€ websocket_manager.py   # WebSocket handling
â”‚   â”‚   â””â”€â”€ middleware/                # FastAPI middleware
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ cors.py
â”‚   â”‚       â””â”€â”€ auth.py
â”‚   â”œâ”€â”€ evaluator_agent/               # ADK agent (existing)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ evaluator_agent.py
â”‚   â”‚   â”œâ”€â”€ run_evaluator_agent.py
â”‚   â”‚   â””â”€â”€ policy_evaluation.py
â”‚   â”œâ”€â”€ models/                        # Pydantic models
â”‚   â”œâ”€â”€ services/                      # Business services
â”‚   â”œâ”€â”€ common/                        # Shared utilities
â”‚   â””â”€â”€ tests/                         # Server tests
â”œâ”€â”€ packages/                          # Frontend packages (OpenCode style)
â”‚   â”œâ”€â”€ sdk/                           # TypeScript/JavaScript SDK
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ client.ts              # Main SDK client
â”‚   â”‚   â”‚   â”œâ”€â”€ types.ts               # Type definitions
â”‚   â”‚   â”‚   â””â”€â”€ websocket.ts           # WebSocket client
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â””â”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ tui/                           # Go TUI package
â”‚   â”‚   â”œâ”€â”€ cmd/                       # CLI commands
â”‚   â”‚   â”œâ”€â”€ internal/                  # Internal packages
â”‚   â”‚   â”œâ”€â”€ sdk/                       # Go SDK (embedded)
â”‚   â”‚   â”œâ”€â”€ input/                     # Input handling
â”‚   â”‚   â”œâ”€â”€ go.mod
â”‚   â”‚   â””â”€â”€ go.sum
â”‚   â””â”€â”€ web/                           # Future web UI
â”‚       â”œâ”€â”€ src/
â”‚       â””â”€â”€ package.json
â”œâ”€â”€ sdks/                              # External SDKs
â”‚   â”œâ”€â”€ python/                        # Python SDK
â”‚   â”‚   â”œâ”€â”€ rogue_sdk/
â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ vscode/                        # VSCode extension
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ rust/                          # Future Rust SDK
â”œâ”€â”€ cli/                               # Standalone CLI application
â”œâ”€â”€ gradio-ui/                         # Standalone Gradio UI
â”œâ”€â”€ pytest-plugin/                    # Pytest integration
â”œâ”€â”€ examples/                          # Usage examples
â”œâ”€â”€ scripts/                           # Build/deployment scripts
â”œâ”€â”€ .github/                           # CI/CD workflows
â”œâ”€â”€ pyproject.toml                     # Python dependencies for server
â”œâ”€â”€ package.json                       # Frontend package management
â”œâ”€â”€ uv.lock                            # Python lock file
â””â”€â”€ README.md
```

## Implementation Phases

### Phase 1: Core Server Infrastructure (Weeks 1-2) âœ… COMPLETED

#### 1.1 Hybrid Monorepo Setup âœ… COMPLETED
- [x] Set up root `package.json` for frontend packages workspace
- [x] Keep `pyproject.toml` for Python server dependencies
- [x] Create `packages/` directory for TypeScript/Go components
- [x] Set up shared TypeScript configuration for frontend packages

#### 1.2 FastAPI Server Package âœ… COMPLETED
- [x] Restructure existing `rogue/` as FastAPI server package
- [x] Implement FastAPI application in `rogue/server/main.py`
- [x] Set up basic middleware (CORS, auth, logging)
- [x] Create health check and status endpoints
- [x] Add WebSocket support for real-time updates

#### 1.2 API Endpoints Design âœ… MOSTLY COMPLETED
- [x] **Evaluation Management**
  - `POST /api/v1/evaluations` - Start new evaluation
  - `GET /api/v1/evaluations/{id}` - Get evaluation status
  - `DELETE /api/v1/evaluations/{id}` - Cancel evaluation
  - `GET /api/v1/evaluations/{id}/results` - Get results
  - `GET /api/v1/evaluations/{id}/report` - Get report

- [x] **Scenario Management** (via LLM endpoints)
  - `POST /api/v1/llm/scenarios` - Generate scenarios
  - `POST /api/v1/llm/summary` - Generate summaries

- [x] **Interview Management**
  - `POST /api/v1/interview/start` - Start interview session
  - `POST /api/v1/interview/message` - Send/receive messages
  - `GET /api/v1/interview/conversation/{id}` - Get conversation
  - `DELETE /api/v1/interview/session/{id}` - End session

- [ ] **Configuration** (PENDING)
  - `GET /api/v1/config` - Get server config
  - `POST /api/v1/config/validate` - Validate configuration
  - `GET /api/v1/agents/{url}/info` - Get agent info

#### 1.3 ADK Agent Integration âœ… COMPLETED
- [x] Create `rogue/server/core/evaluation_orchestrator.py` for evaluation orchestration
- [x] Implement process management for Python ADK agents
- [x] Design communication protocol (CLI args, file I/O, stdout/stderr)
- [x] Update existing `rogue/evaluator_agent/run_evaluator_agent.py` for server integration
- [x] Add progress callback mechanism via HTTP/WebSocket

#### 1.4 WebSocket Support âœ… COMPLETED
- [x] Implement WebSocket manager in `rogue/server/websocket/manager.py`
- [x] Add real-time evaluation updates using FastAPI WebSocket
- [x] Create chat message streaming
- [x] Handle client connection management

#### 1.5 Session Management âœ… COMPLETED
- [x] Create session management in `rogue/server/core/evaluation_orchestrator.py`
- [x] Implement evaluation session tracking
- [x] Add concurrent evaluation support
- [x] Create session cleanup mechanisms

### Phase 2: SDK Development (Week 3) âœ… MOSTLY COMPLETED

#### 2.1 TypeScript SDK (Primary SDK) âœ… COMPLETED
- [x] Create `packages/sdk/` with TypeScript implementation
- [x] Implement main `RogueClient` class with proper typing
- [x] Add WebSocket client for real-time updates
- [x] Create comprehensive type definitions
- [x] Follow OpenCode's SDK patterns and structure

#### 2.2 Python SDK (External) âœ… COMPLETED
- [x] Create `sdks/python/rogue_client/` package structure (renamed from rogue_sdk)
- [x] Implement main `RogueClient` class with full functionality
- [x] Add async client with WebSocket support
- [x] Create request/response models using Pydantic
- [x] Add LLM service methods (generate_scenarios, generate_summary)
- [x] Add interview session management methods

#### 2.2 SDK Features âœ… MOSTLY COMPLETED
- [x] HTTP client for REST API calls
- [x] WebSocket client for real-time updates
- [x] Comprehensive error handling and retry logic
- [ ] Authentication support (PENDING)
- [x] Comprehensive logging and debugging

#### 2.3 SDK Testing & Documentation ğŸ”„ IN PROGRESS
- [ ] Unit tests for all SDK functionality (PENDING)
- [ ] Integration tests with server (PENDING)
- [ ] API documentation with examples (PENDING)
- [ ] Usage examples and tutorials (PENDING)

### Phase 3: Frontend Migration (Weeks 4-5) âœ… COMPLETED

#### 3.1 CLI Refactor âœ… COMPLETED
- [x] Refactor existing CLI in `rogue/run_cli.py` to use Python SDK
- [x] Implement SDK-first approach with legacy fallback
- [x] Add real-time progress display via WebSocket
- [x] Maintain full backward compatibility
- [x] Integrate with all new server endpoints (evaluation, LLM, interview)

#### 3.2 Gradio UI Refactor âœ… COMPLETED
- [x] Refactor existing Gradio UI components to use Python SDK
- [x] Update all components (`scenario_runner.py`, `scenario_generator.py`, `interviewer.py`) to use SDK
- [x] Add WebSocket integration for real-time updates
- [x] Maintain existing UI/UX with enhanced functionality
- [x] Add async support for better performance

#### 3.3 Legacy Support âœ… COMPLETED
- [x] Keep existing `rogue/run_cli.py` and `rogue/run_ui.py` working with SDK-first approach
- [x] Implement graceful fallback to legacy services when server unavailable
- [x] Maintain 100% backward compatibility during transition

### Phase 4: Go TUI Development (Weeks 6-7) âŒ NOT STARTED

#### 4.1 Go SDK Implementation âŒ NOT STARTED
- [ ] Create `sdks/go/` package structure
- [ ] Implement HTTP client for Rogue API
- [ ] Add WebSocket client for real-time updates
- [ ] Create Go structs for API models
- [ ] Add comprehensive error handling

#### 4.2 Bubble Tea TUI (OpenCode Style) âŒ NOT STARTED
- [ ] Set up Go project in `packages/tui/` directory (following OpenCode structure)
- [ ] Create embedded Go SDK in `packages/tui/sdk/`
- [ ] Design TUI screens and navigation using Bubble Tea
- [ ] Implement core components:
  - [ ] Evaluations list view
  - [ ] Evaluation detail view
  - [ ] New evaluation form
  - [ ] Real-time chat display
  - [ ] Progress indicators
  - [ ] Settings screen
  - [ ] commands like `rogue auth login` to setup authentication
- [ ] Add input handling similar to OpenCode's approach

#### 4.3 TUI Features âŒ NOT STARTED
- [ ] Beautiful terminal interface with Lipgloss
- [ ] Keyboard navigation and shortcuts
- [ ] Real-time updates via WebSocket
- [ ] Configuration management
- [ ] Error handling and user feedback

### Phase 5: Additional SDKs & Frontends (Weeks 8-9) âŒ NOT STARTED

#### 5.1 VSCode Extension âŒ NOT STARTED
- [ ] Create `sdks/vscode/` extension package (following OpenCode pattern)
- [ ] Implement extension using TypeScript SDK from `packages/sdk/`
- [ ] Add evaluation management commands
- [ ] Create webview panels for evaluation results
- [ ] Add syntax highlighting for scenario files

#### 5.2 Pytest Plugin âŒ NOT STARTED
- [ ] Create `pytest-plugin/` directory structure
- [ ] Implement pytest fixtures for Rogue client
- [ ] Add test helpers and utilities
- [ ] Create plugin packaging for PyPI
- [ ] Add documentation and examples

#### 5.3 Go SDK Completion âŒ NOT STARTED
- [ ] Complete Go SDK implementation
- [ ] Add comprehensive tests
- [ ] Create Go module for easy import
- [ ] Add documentation and examples

### Phase 6: Testing & Documentation (Week 10) ğŸ”„ PARTIALLY COMPLETED

#### 6.1 Comprehensive Testing ğŸ”„ PARTIALLY COMPLETED
- [x] Basic server component testing (via existing test suite)
- [ ] Integration tests for API endpoints (PENDING)
- [ ] End-to-end tests for complete workflows (PENDING)
- [ ] Performance testing for concurrent evaluations (PENDING)
- [ ] SDK integration tests (PENDING)

#### 6.2 Documentation âŒ NOT STARTED
- [ ] API documentation with OpenAPI/Swagger (PENDING)
- [ ] SDK documentation for all languages (PENDING)
- [ ] Migration guide from legacy architecture (PENDING)
- [ ] Deployment and configuration guides (PENDING)
- [ ] Architecture decision records (ADRs) (PENDING)

#### 6.3 CI/CD Updates âœ… COMPLETED
- [x] Update GitHub Actions workflows (existing workflows working)
- [x] Multi-language testing support (Python + TypeScript)
- [ ] Set up SDK publishing pipelines (PENDING)
- [ ] Add Docker containerization (PENDING)
- [ ] Create deployment scripts (PENDING)

## API Specifications

### REST API Endpoints

#### Evaluation Management
```http
POST /api/v1/evaluations
Content-Type: application/json

{
  "agent_url": "http://localhost:3000",
  "auth_type": "no_auth",
  "auth_credentials": null,
  "scenarios": [...],
  "business_context": "...",
  "judge_llm": "openai/gpt-4",
  "judge_llm_api_key": "...",
  "deep_test_mode": false
}

Response: 201 Created
{
  "id": "eval_123",
  "status": "running",
  "created_at": "2024-01-01T00:00:00Z",
  "progress": 0.0
}
```

#### WebSocket Updates
```javascript
// Connect to evaluation updates
ws://localhost:8000/ws/evaluations/eval_123

// Message types
{
  "type": "status",
  "data": {"message": "Starting evaluation..."},
  "timestamp": "2024-01-01T00:00:00Z"
}

{
  "type": "progress", 
  "data": {"progress": 0.25, "current_scenario": "Don't reveal secrets"},
  "timestamp": "2024-01-01T00:00:00Z"
}

{
  "type": "chat",
  "data": {"role": "Evaluator Agent", "content": "Hello, can you help me?"},
  "timestamp": "2024-01-01T00:00:00Z"
}
```

## SDK Interfaces

### Python SDK
```python
from rogue_sdk import RogueClient, EvaluationRequest, Scenario

client = RogueClient("http://localhost:8000")

# Start evaluation
request = EvaluationRequest(
    agent_url="http://localhost:3000",
    scenarios=[Scenario(scenario="Don't reveal secrets")],
    business_context="Customer service bot",
    judge_llm="openai/gpt-4"
)

evaluation = await client.start_evaluation(request)

# Stream updates
async for update in client.stream_updates(evaluation.id):
    if update.type == "progress":
        print(f"Progress: {update.data['progress']:.1%}")
    elif update.type == "chat":
        print(f"{update.data['role']}: {update.data['content']}")

# Get results
results = await client.get_results(evaluation.id)
```

### Go SDK
```go
package main

import (
    "context"
    "github.com/your-org/rogue-go-sdk/client"
)

func main() {
    client := client.NewRogueClient("http://localhost:8000")
    
    req := client.EvaluationRequest{
        AgentURL: "http://localhost:3000",
        Scenarios: []client.Scenario{
            {Scenario: "Don't reveal secrets"},
        },
        BusinessContext: "Customer service bot",
        JudgeLLM: "openai/gpt-4",
    }
    
    eval, err := client.StartEvaluation(context.Background(), req)
    if err != nil {
        panic(err)
    }
    
    // Stream updates
    updates, err := client.StreamUpdates(context.Background(), eval.ID)
    for update := range updates {
        if update.Type == "progress" {
            fmt.Printf("Progress: %.1f%%\n", update.Data["progress"].(float64)*100)
        }
    }
}
```

## Migration Strategy

### Backward Compatibility
1. **Phase 1-3**: Keep existing CLI and UI working alongside new server
2. **Phase 4-6**: Add deprecation warnings to legacy components
3. **Post-launch**: Provide 6-month deprecation period before removing legacy code

### Data Migration
- Existing configuration files remain compatible
- Scenario files use same JSON format
- Results format unchanged for backward compatibility

### User Migration Path
1. **Immediate**: Users can continue using existing CLI/UI
2. **Gradual**: Users can opt-in to new server-based architecture
3. **Future**: Legacy components deprecated with clear migration path

## Risk Mitigation

### Technical Risks
- **ADK Agent Integration**: Extensive testing of process communication
- **WebSocket Stability**: Robust connection handling and reconnection logic
- **Concurrent Evaluations**: Thorough testing of resource management

### User Experience Risks
- **Feature Parity**: Ensure all existing features work in new architecture
- **Performance**: Maintain or improve evaluation performance
- **Learning Curve**: Comprehensive documentation and examples

### Deployment Risks
- **Backward Compatibility**: Extensive testing of legacy component compatibility
- **SDK Stability**: Comprehensive testing across all supported languages
- **Documentation**: Clear migration guides and troubleshooting

## Success Metrics

### Technical Metrics
- [ ] All existing functionality preserved
- [ ] API response times < 100ms for non-evaluation endpoints
- [ ] WebSocket connection stability > 99.9%
- [ ] Support for 10+ concurrent evaluations

### User Experience Metrics
- [ ] Zero breaking changes for existing users during transition
- [ ] New TUI provides superior user experience
- [ ] SDK adoption by external developers
- [ ] Reduced time-to-value for new integrations

### Development Metrics
- [ ] 90%+ test coverage across all components
- [ ] Complete API documentation
- [ ] SDK documentation for all languages
- [ ] Successful CI/CD pipeline for all components

## Timeline Summary

| Phase | Status | Key Deliverables |
|-------|--------|------------------|
| Phase 1 | âœ… COMPLETED | FastAPI server, ADK integration, WebSocket support |
| Phase 2 | âœ… COMPLETED | Python & TypeScript SDKs with full functionality |
| Phase 3 | âœ… COMPLETED | Refactored CLI and Gradio UI using SDK |
| Phase 4 | âŒ NOT STARTED | Go SDK and Bubble Tea TUI |
| Phase 5 | âŒ NOT STARTED | VSCode extension, pytest plugin |
| Phase 6 | ğŸ”„ PARTIAL | Testing, documentation, CI/CD |

## CURRENT STATUS: Phase 3 Complete - Server-Client Architecture Fully Operational

### âœ… MAJOR ACHIEVEMENTS
- **Complete server-client architecture** with FastAPI backend
- **Full SDK ecosystem** (Python + TypeScript) with comprehensive functionality
- **Seamless migration** of CLI and UI to SDK-first approach with legacy fallback
- **Real-time capabilities** via WebSocket integration
- **Production-ready** server with proper session management and error handling


## Next Steps - Post Phase 3 Completion

### IMMEDIATE PRIORITIES (Choose One Path):

#### Path A: Complete Core Platform (Recommended)
1. **Phase 6+ Completion**: Focus on testing, documentation, and production readiness
   - Add comprehensive API documentation with OpenAPI/Swagger
   - Create SDK integration tests and end-to-end testing
   - Add Docker containerization for easy deployment
   - Create proper deployment and configuration guides

#### Path B: Expand Platform Capabilities
2. **Phase 4 Implementation**: Add Go TUI for enhanced developer experience
   - Implement Go SDK with full API coverage
   - Create beautiful Bubble Tea TUI following OpenCode patterns
   - Add advanced terminal-based evaluation management

#### Path C: Developer Ecosystem
3. **Phase 5 Implementation**: Build developer tools and integrations
   - Create VSCode extension for in-editor evaluation management
   - Implement pytest plugin for test-driven agent evaluation
   - Add additional language SDKs (Rust, etc.)

### RECOMMENDED APPROACH:
**Start with Path A** to ensure the core platform is production-ready, then move to Path B or C based on user feedback and adoption needs.

### CURRENT ARCHITECTURE STATUS:
- âœ… **Server-Client Architecture**: Fully operational
- âœ… **SDK Ecosystem**: Complete and functional
- âœ… **Legacy Compatibility**: 100% maintained
- âœ… **Real-time Features**: WebSocket integration working
- ğŸ”„ **Production Readiness**: Needs documentation and testing improvements

---

## Phase 6+: Production Readiness & Platform Expansion (DETAILED PLAN)

### **RECOMMENDATION: Path A - Complete Core Platform**

Based on current state analysis, focusing on **Path A: Production Readiness** is the optimal next phase. Here's the detailed implementation plan:

### **Phase 6.1: Testing & Quality Assurance (Weeks 1-2)**

#### **6.1.1 API Testing Suite**
- [ ] **Integration tests** for all server endpoints (`/api/v1/evaluations`, `/api/v1/llm/*`, `/api/v1/interview/*`)
- [ ] **WebSocket testing** for real-time functionality and connection stability
- [ ] **Error handling tests** for edge cases and failure scenarios
- [ ] **Concurrent evaluation testing** to ensure scalability (10+ concurrent evaluations)

#### **6.1.2 SDK Testing Suite**
- [ ] **Python SDK integration tests** with live server
- [ ] **TypeScript SDK integration tests** with live server  
- [ ] **Cross-SDK compatibility tests** (Python client â†’ TS server, etc.)
- [ ] **WebSocket client testing** for both SDKs with reconnection logic

#### **6.1.3 End-to-End Testing**
- [ ] **Complete workflow tests** (CLI â†’ Server â†’ Agent â†’ Results)
- [ ] **UI workflow tests** (Gradio â†’ Server â†’ Agent â†’ Results)
- [ ] **Legacy fallback testing** (server down scenarios)
- [ ] **Performance benchmarking** (concurrent evaluations, memory usage, response times)

### **Phase 6.2: Documentation & Developer Experience (Weeks 2-3)**

#### **6.2.1 API Documentation**
- [ ] **OpenAPI/Swagger integration** with FastAPI auto-docs at `/docs` endpoint
- [ ] **Interactive API explorer** with request/response examples
- [ ] **WebSocket protocol documentation** with message types and examples
- [ ] **Authentication documentation** (when implemented)

#### **6.2.2 SDK Documentation**
- [ ] **Python SDK documentation** with comprehensive examples and tutorials
- [ ] **TypeScript SDK documentation** with examples and tutorials
- [ ] **Migration guide** from legacy to SDK-first approach
- [ ] **Troubleshooting guide** for common issues and error scenarios

#### **6.2.3 Deployment Documentation**
- [ ] **Docker containerization guide** with multi-stage builds
- [ ] **Environment configuration guide** with all variables documented
- [ ] **Production deployment checklist** with security considerations
- [ ] **Monitoring and logging setup** with recommended tools

### **Phase 6.3: Production Infrastructure (Weeks 3-4)**

#### **6.3.1 Containerization**
- [ ] **Multi-stage Docker build** for server with optimized image size
- [ ] **Docker Compose** for development environment with all services
- [ ] **Health checks** and proper shutdown handling for graceful restarts
- [ ] **Environment variable management** with validation and defaults

#### **6.3.2 CI/CD Enhancements**
- [ ] **Automated testing pipeline** for all components (server, SDKs, integration)
- [ ] **SDK publishing automation** (PyPI for Python, npm for TypeScript)
- [ ] **Docker image publishing** to container registry with versioning
- [ ] **Release automation** with proper semantic versioning and changelogs

#### **6.3.3 Monitoring & Observability**
- [ ] **Structured logging** throughout the application with correlation IDs
- [ ] **Metrics collection** (evaluation counts, performance, errors, WebSocket connections)
- [ ] **Health monitoring** endpoints for load balancers and orchestrators
- [ ] **Error tracking** and alerting with proper categorization

### **Phase 6.4: Polish & Optimization (Weeks 4-5)**

#### **6.4.1 Performance Optimization**
- [ ] **Memory usage optimization** for concurrent evaluations
- [ ] **WebSocket connection pooling** and management improvements
- [ ] **Caching strategy** for frequently accessed data (scenarios, configurations)
- [ ] **Database optimization** (if applicable) with proper indexing

#### **6.4.2 Security Hardening**
- [ ] **Authentication system** implementation (JWT, API keys, or OAuth)
- [ ] **Rate limiting** for API endpoints to prevent abuse
- [ ] **Input validation** and sanitization across all endpoints
- [ ] **Security headers** and CORS configuration for production

#### **6.4.3 User Experience Polish**
- [ ] **Error message improvements** across all interfaces with actionable guidance
- [ ] **Loading states** and progress indicators for all async operations
- [ ] **Configuration validation** with helpful error messages and suggestions
- [ ] **CLI help text** improvements and command discoverability

### **Success Metrics for Phase 6+**

#### **Technical Metrics**
- [ ] **90%+ test coverage** across server and SDKs
- [ ] **API response times < 100ms** for non-evaluation endpoints
- [ ] **WebSocket connection stability > 99.9%** with proper reconnection
- [ ] **Support for 10+ concurrent evaluations** without performance degradation
- [ ] **Memory usage < 512MB** per concurrent evaluation

#### **Developer Experience Metrics**
- [ ] **Complete API documentation** with interactive examples
- [ ] **SDK documentation** with tutorials and real-world examples
- [ ] **One-command deployment** via Docker with all dependencies
- [ ] **Automated CI/CD pipeline** with zero manual intervention
- [ ] **< 5 minute setup time** for new developers

#### **Production Readiness Metrics**
- [ ] **Docker containerization** with health checks and graceful shutdown
- [ ] **Monitoring and logging** infrastructure with alerting
- [ ] **Security hardening** complete with authentication and rate limiting
- [ ] **Performance benchmarking** results documented and validated
- [ ] **Load testing** completed for expected production traffic

### **Timeline Estimate**

| Sub-Phase | Duration | Key Deliverables | Success Criteria |
|-----------|----------|------------------|------------------|
| 6.1 Testing | 2 weeks | Complete test suite, performance benchmarks | 90%+ coverage, all tests passing |
| 6.2 Documentation | 1 week | API docs, SDK docs, deployment guides | Complete documentation, examples working |
| 6.3 Infrastructure | 1 week | Docker, CI/CD, monitoring | One-command deployment, automated pipelines |
| 6.4 Polish | 1 week | Performance, security, UX improvements | Production-ready platform |

**Total: 5 weeks to production-ready platform**

### **Why This Path Makes Sense**

1. **Foundation First**: Solid testing and documentation before expanding capabilities
2. **User Confidence**: Production-ready platform builds trust and adoption
3. **Maintainability**: Proper testing prevents regressions as we add features
4. **Developer Onboarding**: Good documentation accelerates new contributor onboarding
5. **Deployment Ready**: Docker and CI/CD enable easy deployment and scaling
6. **Performance Validated**: Benchmarking ensures the platform can handle real-world usage

### **Post Phase 6+ Options**

After completing Phase 6+, the platform will be production-ready and we can choose:

- **Path B**: Go TUI Development for enhanced terminal experience
- **Path C**: Developer Ecosystem (VSCode extension, pytest plugin)
- **Path D**: Advanced Features (authentication, multi-tenancy, advanced analytics)

This approach ensures the core platform is rock-solid before expanding into new frontends or capabilities.

## Key Insights from OpenCode Architecture

Based on OpenCode's successful implementation, here are key architectural decisions to adopt:

### 1. **Monorepo with Packages**
- Use `packages/` directory for core components
- Each package has its own `package.json` and dependencies
- Shared TypeScript configuration across packages
- Workspace-based dependency management with Bun/npm

### 2. **FastAPI Server with TypeScript Frontends**
- Core server remains in Python with FastAPI (for ADK compatibility)
- TypeScript SDKs and frontends for modern developer experience
- OpenAPI/JSON Schema for automatic type generation
- Python async/await patterns with FastAPI's excellent async support

### 3. **Event Bus Architecture**
- Internal event bus for component communication
- Decoupled architecture with pub/sub patterns
- Better scalability and maintainability
- Real-time updates via WebSocket integration

### 4. **Go TUI with Embedded SDK**
- TUI package includes its own Go SDK in `packages/tui/sdk/`
- Self-contained binary with no external dependencies
- Follows Go best practices for CLI tools
- Input handling and terminal management

### 5. **Multiple SDK Strategies**
- Primary TypeScript SDK in `packages/sdk/`
- Language-specific SDKs in `sdks/` directory
- VSCode extension using primary SDK
- Clear separation between internal and external SDKs

### 6. **Python-First Server with Modern Frontends**
- FastAPI server maintains Python ecosystem compatibility
- Existing Python ADK agent works seamlessly
- Modern TypeScript/Go frontends communicate via HTTP/WebSocket
- Best of both worlds: Python ML/AI ecosystem + modern frontend tooling

### 7. **Hybrid Build Strategy**
- Python server: `uv` for dependency management and packaging
- Frontend packages: Modern JavaScript tooling (Bun, Vite, etc.)
- Go TUI: Standard Go build tools and cross-compilation
- Multiple distribution channels: PyPI (server), npm (SDK), Homebrew (TUI)

---

*This document will be updated as the refactor progresses and requirements evolve.*
