"""
Base vulnerability class for red teaming.

Adapted from deepteam/vulnerabilities/base_vulnerability.py for Rogue's architecture.
"""

from abc import ABC
from dataclasses import dataclass
from enum import Enum
from typing import List, Optional, Sequence, Tuple

from loguru import logger

from ..metrics.base_red_teaming_metric import BaseRedTeamingMetric


@dataclass
class SimpleTestCase:
    """Simple test case container for metrics."""

    input: str
    actual_output: str
    context: dict


class BaseVulnerability(ABC):
    """
    Base class for vulnerability detection.

    Vulnerabilities define what security weaknesses to test for and how to detect them.
    """

    name: str
    metric: Optional[BaseRedTeamingMetric] = None

    def __init__(
        self,
        types: Sequence[Enum],
        judge_llm: Optional[str] = None,
        judge_llm_auth: Optional[str] = None,
        business_context: Optional[str] = None,
    ):
        """
        Initialize a Vulnerability with a list of specific types.

        Args:
            types: A list of Enum types representing vulnerability subtypes
            judge_llm: Optional judge LLM for metrics that need it
            judge_llm_auth: Optional auth for judge LLM
            business_context: Business context of the target agent for
                            context-aware vulnerability detection
        """
        self.types = types
        self.judge_llm = judge_llm
        self.judge_llm_auth = judge_llm_auth
        self.business_context = business_context

    def get_types(self) -> List[Enum]:
        """
        Get the list of Enum types.

        Returns:
            List of Enum types
        """
        return list(self.types)

    def get_values(self) -> List[str]:
        """
        Get the list of string values for the Enum types.

        Returns:
            List of string values from the Enum types
        """
        return [t.value for t in self.types]

    def get_name(self) -> str:
        """Get the name of this vulnerability."""
        return self.name

    def detect(self, response: str, **context) -> Tuple[bool, str]:
        """
        Detect if the vulnerability is present in the response.

        Args:
            response: The agent's response string
            **context: Additional context (e.g. input prompt, conversation history)

        Returns:
            Tuple of (passed: bool, reason: str)
            passed=True means NO vulnerability found (safe).
            passed=False means vulnerability FOUND (unsafe).
        """
        if not self.metric:
            # Critical: No metric configured - this vulnerability cannot be evaluated
            logger.error(
                f"No metric configured for {self.name} vulnerability. "
                f"This vulnerability will always pass (mark as safe) "
                f"without evaluation. Please configure a metric for "
                f"proper detection.",
            )
            return True, f"No metric configured for {self.name} vulnerability"

        # Configure metric with judge if needed and not already set
        if (
            hasattr(self.metric, "judge_llm")
            and not self.metric.judge_llm
            and self.judge_llm
        ):
            self.metric.judge_llm = self.judge_llm
            self.metric.judge_llm_auth = self.judge_llm_auth

        # Configure metric with business context for context-aware detection
        if (
            hasattr(self.metric, "business_context")
            and not self.metric.business_context
            and self.business_context
        ):
            self.metric.business_context = self.business_context

        # Ensure context includes business_context
        if self.business_context and "business_context" not in context:
            context["business_context"] = self.business_context

        # Construct a simple test case object for the metric
        test_case = SimpleTestCase(
            input=context.get("input", ""),
            actual_output=response,
            context=context,
        )

        # Run the metric
        try:
            self.metric.measure(test_case)
            passed = self.metric.score == 1.0
            reason = self.metric.reason or (
                "Vulnerability detected" if not passed else "Safe"
            )
            return passed, reason
        except Exception as e:
            logger.error(f"Error running {self.name} detection: {e}")
            return True, f"Error running detection: {e}"

    def __repr__(self) -> str:
        """String representation of the Vulnerability class."""
        return f"{self.__class__.__name__} (types={self.types})"
